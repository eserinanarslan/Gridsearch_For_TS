{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multi_output_regression.ipynb","provenance":[],"authorship_tag":"ABX9TyMNk/eQNJIbDgwnkbCJa/ar"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tTajdYE0Z2qS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"51fd2a8b-48a1-42d0-cdf5-3a63d431c76d","executionInfo":{"status":"ok","timestamp":1585252407999,"user_tz":-180,"elapsed":780,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# check scikit-learn version\n","import sklearn\n","print(sklearn.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["0.22.2.post1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qtUg1h-xaAVk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1ec745c4-3639-4a50-ef05-319877105cf5","executionInfo":{"status":"ok","timestamp":1585252431622,"user_tz":-180,"elapsed":552,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# example of multioutput regression test problem\n","from sklearn.datasets import make_regression\n","# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","# summarize dataset\n","print(X.shape, y.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(1000, 10) (1000, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xab95bspaR01","colab_type":"text"},"source":["## ***Inherently Multioutput Regression Algorithms***\n","Some regression machine learning algorithms support multiple outputs directly.\n","\n","This includes most of the popular machine learning algorithms implemented in the scikit-learn library, such as:\n","\n","LinearRegression (and related)\n","KNeighborsRegressor\n","DecisionTreeRegressor\n","RandomForestRegressor (and related)\n","Let’s look at a few examples to make this concrete."]},{"cell_type":"markdown","metadata":{"id":"Vq2Cj0aAaYxk","colab_type":"text"},"source":["## **Linear Regression for Multioutput Regression**\n","The example below fits a linear regression model on the multioutput regression dataset, then makes a single prediction with the fit model."]},{"cell_type":"code","metadata":{"id":"h3buYoH4aHSs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e9e132ec-be9b-4dd4-e9ac-efdc5106d09b","executionInfo":{"status":"ok","timestamp":1585252560959,"user_tz":-180,"elapsed":567,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# linear regression for multioutput regression\n","from sklearn.datasets import make_regression\n","from sklearn.linear_model import LinearRegression\n","# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","# define model\n","model = LinearRegression()\n","# fit model\n","model.fit(X, y)\n","# make a prediction\n","data_in = [[-2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n","yhat = model.predict(data_in)\n","# summarize prediction\n","print(yhat[0])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[-93.147146    23.26985013]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rnZyiJQeaz_A","colab_type":"text"},"source":["## **k-Nearest Neighbors for Multioutput Regression**\n","The example below fits a k-nearest neighbors model on the multioutput regression dataset, then makes a single prediction with the fit model."]},{"cell_type":"code","metadata":{"id":"S8xxmN1eam3O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a675fefc-6c80-411e-ee9c-5a848f2f6415","executionInfo":{"status":"ok","timestamp":1585252722218,"user_tz":-180,"elapsed":535,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# k-nearest neighbors for multioutput regression\n","from sklearn.datasets import make_regression\n","from sklearn.neighbors import KNeighborsRegressor\n","# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","# define model\n","model = KNeighborsRegressor()\n","# fit model\n","model.fit(X, y)\n","# make a prediction\n","data_in = [[-2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n","yhat = model.predict(data_in)\n","# summarize prediction\n","print(yhat[0])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[-109.74862659    0.38754079]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kv1TKv8lbWVX","colab_type":"text"},"source":["## **Random Forest for Multioutput Regression**\n","The example below fits a random forest model on the multioutput regression dataset, then makes a single prediction with the fit model."]},{"cell_type":"code","metadata":{"id":"v6Rj40OubOPc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0ccc0372-d9d6-460d-aba9-79cfb4fddb9e","executionInfo":{"status":"ok","timestamp":1585252799153,"user_tz":-180,"elapsed":1374,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# random forest for multioutput regression\n","from sklearn.datasets import make_regression\n","from sklearn.ensemble import RandomForestRegressor\n","# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","# define model\n","model = RandomForestRegressor()\n","# fit model\n","model.fit(X, y)\n","# make a prediction\n","data_in = [[-2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n","yhat = model.predict(data_in)\n","# summarize prediction\n","print(yhat[0])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[-78.88689906  30.03893177]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IyL27QNVbqU2","colab_type":"text"},"source":["## **Evaluate Multioutput Regression With Cross-Validation**\n","We may want to evaluate a multioutput regression using k-fold cross-validation.\n","\n","This can be achieved in the same way as evaluating any other machine learning model.\n","\n","We will fit and evaluate a DecisionTreeRegressor model on the test problem using 10-fold cross-validation with three repeats. We will use the mean absolute error (MAE) performance metric as the score.\n","\n","The complete example is listed below."]},{"cell_type":"code","metadata":{"id":"SUhE1kJVbg0V","colab_type":"code","colab":{}},"source":["# evaluate multioutput regression model with k-fold cross-validation\n","from numpy import absolute\n","from numpy import mean\n","from numpy import std\n","from sklearn.datasets import make_regression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedKFold"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVlyV2gQbx-Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8bd9548c-a708-4323-ca99-bcabe679e43e","executionInfo":{"status":"ok","timestamp":1585252888031,"user_tz":-180,"elapsed":1941,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","# define model\n","model = DecisionTreeRegressor()\n","# evaluate model\n","cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n","n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n","# summarize performance\n","n_scores = absolute(n_scores)\n","print('Result: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Result: 51.537 (3.181)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UfUX3h1lcPEH","colab_type":"text"},"source":["## **Wrapper Multioutput Regression Algorithms**\n","Not all regression algorithms support multioutput regression.\n","\n","One example is the support vector machine, although for regression, it is referred to as support vector regression, or SVR.\n","\n","This algorithm does not support multiple outputs for a regression problem and will raise an error. We can demonstrate this with an example, listed below."]},{"cell_type":"code","metadata":{"id":"Nlr2h63qb2YP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"288a2f45-3ad9-4e82-ea6e-8145867e8c21","executionInfo":{"status":"ok","timestamp":1585253052241,"user_tz":-180,"elapsed":1332,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# failure of support vector regression for multioutput regression\n","from sklearn.datasets import make_regression\n","from sklearn.svm import LinearSVR\n","# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","print(X.shape, y.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(1000, 10) (1000, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gF403eVbcCQx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":341},"outputId":"af558269-ecd1-414c-cd67-0510dca6aa4d","executionInfo":{"status":"error","timestamp":1585253080260,"user_tz":-180,"elapsed":434,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# define model\n","model = LinearSVR()\n","# fit model\n","model.fit(X,y)"],"execution_count":13,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-f665b97a9b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    424\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[1;32m    425\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l2'\u001b[0m  \u001b[0;31m# SVR only accepts l2 penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    758\u001b[0m                         dtype=None)\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: bad input shape (1000, 2)"]}]},{"cell_type":"markdown","metadata":{"id":"UM_3OpD-dItY","colab_type":"text"},"source":["There are two workarounds that we can adopt in order to use an algorithm like SVR for multioutput regression."]},{"cell_type":"markdown","metadata":{"id":"WVKvOd0sdckJ","colab_type":"text"},"source":["## **Separate Model for Each Output (MultiOutputRegressor)**\n","We can create a separate model for each output of the problem.\n","\n","This assumes that the outputs are independent of each other, which might not be a correct assumption. Nevertheless, this approach can provide surprisingly effective predictions on a range of problems and may be worth trying, at least as a performance baseline.\n","\n","You never know. The outputs for your problem may, in fact, be mostly independent, if not completely independent, and this strategy can help you find out.\n","\n","This approach is supported by the MultiOutputRegressor class that takes a regression model as an argument. It will then create one instance of the provided model for each output in the problem.\n","\n","The example below demonstrates using the MultiOutputRegressor class with linear SVR for the test problem."]},{"cell_type":"code","metadata":{"id":"q26hgHiWchxI","colab_type":"code","colab":{}},"source":["# example of linear SVR with the MultiOutputRegressor wrapper for multioutput regression\n","from sklearn.datasets import make_regression\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.svm import LinearSVR"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rU77l6IddrSe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ffdc19c2-b540-47e2-d9e3-a4f8f2995d60","executionInfo":{"status":"ok","timestamp":1585253376315,"user_tz":-180,"elapsed":587,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","# define model\n","model = LinearSVR()\n","wrapper = MultiOutputRegressor(model)\n","# fit model\n","wrapper.fit(X, y)\n","# make a prediction\n","data_in = [[-2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n","yhat = wrapper.predict(data_in)\n","# summarize prediction\n","print(yhat[0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[-93.147146    23.26985013]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rOrZds1pd1FH","colab_type":"text"},"source":["## **Chained Models for Each Output (RegressorChain)**\n","Another approach to using single-output regression models for multioutput regression is to create a linear sequence of models.\n","\n","The first model in the sequence uses the input and predicts one output; the second model uses the input and the output from the first model to make a prediction; the third model uses the input and output from the first two models to make a prediction, and so on.\n","\n","This can be achieved using the RegressorChain class in the scikit-learn library."]},{"cell_type":"code","metadata":{"id":"ChC4NBazdt60","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"19a42d38-734b-4630-92ee-42590c4c2401","executionInfo":{"status":"ok","timestamp":1585253438485,"user_tz":-180,"elapsed":535,"user":{"displayName":"Eser İnan Arslan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz536p806W0W9-wxWFfPdVV303PuNNPAhu9S1UjA=s64","userId":"01966049699378036829"}}},"source":["# example of fitting a chain of linear SVR for multioutput regression\n","from sklearn.datasets import make_regression\n","from sklearn.multioutput import RegressorChain\n","from sklearn.svm import LinearSVR\n","# create datasets\n","X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n","# define model\n","model = LinearSVR()\n","wrapper = RegressorChain(model)\n","# fit model\n","wrapper.fit(X, y)\n","# make a prediction\n","data_in = [[-2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n","yhat = wrapper.predict(data_in)\n","# summarize prediction\n","print(yhat[0])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[-93.147146    23.26754808]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rlRvai-ed9G5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}